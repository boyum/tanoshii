# Tanoshii (楽しい)

A Japanese vocabulary learning app with reading practice, AI-generated sentences, and conversation practice.

## Features

- **Reading Practice**: Practice reading Japanese sentences and stories generated by AI
- **Furigana & Romaji**: Toggle reading aids for kanji
- **Text-to-Speech**: Listen to native Japanese pronunciation
- **Conversation Mode**: Practice speaking Japanese with an AI conversation partner
- **JLPT N5 Level**: Content designed for beginner learners

## Quick Start

### Option 1: Using Google Gemini (Free, Cloud-based) ⭐ Easiest

No GPU or powerful computer needed! Uses Google's free Gemini API.

```bash
git clone https://github.com/boyum/tanoshii
cd tanoshii

# Get your free API key from https://aistudio.google.com/app/apikey
export GOOGLE_AI_API_KEY="your-api-key-here"

# Edit application.yml and change provider from "ollama" to "gemini"
# (See GEMINI_QUICK_START.md for detailed steps)

./gradlew run
```

**Gemini Free Tier**: 15 requests/min, 1M tokens/day (enough for 10-50 users)

See [GEMINI_SETUP.md](GEMINI_SETUP.md) for detailed instructions.

### Option 2: Using Ollama (Local, Self-hosted)

```bash
git clone https://github.com/boyum/tanoshii
cd tanoshii
make init-mac  # Installs dependencies and creates .env with Ollama config
make start     # Auto-starts with Ollama
```

Then open **<http://localhost:8080>** in your browser.

**Switching Providers:**
If you have both Ollama and Gemini configured, `make start` will prompt you to choose:

```bash
make start

# Output:
# Both Ollama and Gemini are available!
# Choose your LLM provider:
#   1) Ollama (local, private, free)
#   2) Gemini (cloud, fast, free tier)
# Enter choice (1 or 2):
```

Or use specific commands:

- `make start-with-ollama` - Force Ollama
- `make start-with-gemini` - Force Gemini

See [MAKEFILE_USAGE.md](MAKEFILE_USAGE.md) for all commands.

## Docker Setup (Recommended for All Platforms)

If you have Docker installed, this is the easiest way to run Tanoshii:

```bash
git clone https://github.com/boyum/tanoshii
cd tanoshii
docker-compose up -d
```

That's it! The first startup will take several minutes as it:

- Builds the application
- Downloads the Ollama LLM (Qwen 2.5, ~4.7 GB)
- Sets up the database

Once running, open **<http://localhost:8080>** in your browser.

### Docker Commands

```bash
docker-compose up -d        # Start all services in background
docker-compose logs -f app  # View application logs
docker-compose logs -f ollama # View Ollama logs
docker-compose down         # Stop all services
docker-compose down -v      # Stop and remove all data (fresh start)
docker-compose restart app  # Restart just the app
```

### Custom Vocabulary with Docker

Place your CSV files in the `known-words/` directory before starting:

```bash
mkdir -p known-words
# Add your CSV files to known-words/
docker-compose up -d
```

The `known-words/` directory is automatically mounted into the container.

**For detailed Docker documentation, see [DOCKER.md](DOCKER.md)**

## Requirements

### Docker Setup

- Docker and Docker Compose
- At least 8 GB of free disk space (for LLM model)
- 4 GB RAM minimum (8 GB recommended)

### Native Setup (macOS)

- macOS (Apple Silicon M1/M2/M3/M4 recommended)
- Java 17+
- Python 3.9+
- Ollama (for AI text generation)

## Available Commands

```bash
make help         # Show all available commands
make init-mac     # Full setup (installs Java, Python, Ollama, pulls model)
make start        # Start Ollama and the app
make stop         # Stop all services
make dev          # Start in dev mode (auto-restart on code changes)
make clean        # Clean build artifacts and database
```

## Manual Setup

If you prefer to set things up manually or aren't on macOS:

### 1. Install Dependencies

- **Java 17**: `brew install openjdk@17`
- **Python 3**: `brew install python@3.11`
- **Ollama**: `brew install ollama`

Add Java to your shell profile (`~/.zshrc`):

```bash
export JAVA_HOME=/opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk/Contents/Home
export PATH="$JAVA_HOME/bin:$PATH"
```

### 2. Setup Ollama

```bash
ollama serve                 # Start the service
ollama pull qwen2.5:7b       # Pull the model (in another terminal)
```

### 3. Setup Python Environment

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r scripts/requirements.txt
```

### 4. Run the Application

```bash
./gradlew run
```

The app will be available at: **<http://localhost:8080>**

## Custom Vocabulary

By default, the app uses built-in JLPT N5/N4 vocabulary. To add your own words, create CSV files in `known-words/`:

```csv
japanese;romaji;english
猫;neko;cat
犬;inu;dog
学校;gakkou;school
```

Note: Fields are separated by semicolons (`;`).

## Usage

### Reading Practice

1. Choose a difficulty level (Easy/Medium/Hard)
2. Click "Start Session"
3. Read the Japanese text
4. Use the toggle buttons for Furigana/Romaji if needed
5. Click the speaker button to hear pronunciation
6. Click "Show Translation" to see the English meaning

### Conversation Practice

1. Click "Conversation Practice" on the home page
2. Select a scenario (restaurant, shopping, etc.)
3. Hold the microphone button and speak in Japanese
4. The AI will respond with voice

## Configuration

Edit `src/main/resources/application.yml` to customize:

```yaml
ollama:
  base-url: http://localhost:11434 # Ollama server URL
  model: qwen2.5:7b # Model to use

edge-tts:
  voice: ja-JP-NanamiNeural # Japanese voice for TTS
```

## Troubleshooting

### Docker: Services not starting

Check the logs:

```bash
docker-compose logs -f
```

If Ollama is still downloading the model, wait a few more minutes. You can monitor progress:

```bash
docker-compose logs -f ollama
```

### Docker: Application can't connect to Ollama

The app starts before the LLM model finishes downloading. Once the model is ready, restart the app:

```bash
docker-compose restart app
```

### Docker: Fresh start

To completely reset and remove all data:

```bash
docker-compose down -v
docker-compose up -d
```

### Ollama not responding

Make sure the Ollama service is running:

```bash
ollama serve
```

### Audio not playing

The app uses Edge TTS which requires an internet connection for the first audio generation.

### Whisper model download

On first use of conversation mode, the Whisper model will be downloaded (~500MB for "small" model). This may take a few minutes.

### Java version issues

Verify Java 17 is being used:

```bash
java -version
```

Should show version 17.x.x

## Tech Stack

- **Backend**: Kotlin + Micronaut
- **Frontend**: Thymeleaf + HTMX
- **AI**: Ollama (Qwen 2.5)
- **TTS**: Edge TTS (Microsoft)
- **STT**: Faster Whisper
- **Japanese Processing**: Kuromoji (furigana/romaji)
- **Database**: SQLite

## License

MIT

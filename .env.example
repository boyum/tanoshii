# LLM Provider Configuration
# Options: "ollama" (local) or "gemini" (Google AI)
LLM_PROVIDER=ollama

# LLM Model name
# For Ollama: qwen2.5:7b, llama3:8b, etc.
# For Gemini: gemini-3-flash-preview, gemini-1.5-pro, etc.
LLM_MODEL=qwen2.5:7b

# Google Gemini API Key (only needed if LLM_PROVIDER=gemini)
# Get your key at: https://aistudio.google.com/app/apikey
GOOGLE_AI_API_KEY=your-api-key-here

# Ollama Configuration (only needed if LLM_PROVIDER=ollama)
# Note: With Gemini SDK, LLM_BASE_URL is not used
LLM_BASE_URL=http://localhost:11434
